{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07ca0d46-427a-43b9-a62f-c1a39a1ce6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import gensim\n",
    "import gensim.downloader as gensim_api\n",
    "from nltk import word_tokenize\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## load custom stop words\n",
    "lst_stopwords = pd.read_csv(\"./lst_custom_stopwords.txt\")\n",
    "lst_stopwords = lst_stopwords[\"header\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26676f22-1d4f-4718-a907-83f2e43e6116",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"./data/posts2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e68b6114-e0a1-4670-a6b7-4d7a7d0005de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Filipino clients may not take pain medication ...</td>\n",
       "      <td>Present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I miss my lil Percocet phase ðŸ˜‚ðŸ˜‚ I c y niggas t...</td>\n",
       "      <td>Past</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I can not sleep so maybe I will use tramadol</td>\n",
       "      <td>Future</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iâ€™ve got opiate-withdrawal leg muscle spasms t...</td>\n",
       "      <td>Present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>there is no better taste than oxycodone in the...</td>\n",
       "      <td>Present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>Nope 10 year oxycodone run. But they tested me...</td>\n",
       "      <td>Past</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>I appreciate it a lot. Im 19 been addicted for...</td>\n",
       "      <td>Present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>I gotta yeast overgrowth from kratom and it ru...</td>\n",
       "      <td>Present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>Kratom gave me a yeast overgrowth and ruin my ...</td>\n",
       "      <td>Past</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>Iâ€™m in the same boat. At work now on day 1. Ju...</td>\n",
       "      <td>Present</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>648 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   doc    label\n",
       "0    Filipino clients may not take pain medication ...  Present\n",
       "1    I miss my lil Percocet phase ðŸ˜‚ðŸ˜‚ I c y niggas t...     Past\n",
       "2         I can not sleep so maybe I will use tramadol   Future\n",
       "3    Iâ€™ve got opiate-withdrawal leg muscle spasms t...  Present\n",
       "4    there is no better taste than oxycodone in the...  Present\n",
       "..                                                 ...      ...\n",
       "643  Nope 10 year oxycodone run. But they tested me...     Past\n",
       "644  I appreciate it a lot. Im 19 been addicted for...  Present\n",
       "645  I gotta yeast overgrowth from kratom and it ru...  Present\n",
       "646  Kratom gave me a yeast overgrowth and ruin my ...     Past\n",
       "647  Iâ€™m in the same boat. At work now on day 1. Ju...  Present\n",
       "\n",
       "[648 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "804d6683-a6f8-492b-a35b-b656f3d65d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text, use_stem=False, use_lemm=True, lst_stopwords=None):\n",
    "    \n",
    "    ## de-construct contractions\n",
    "    text = re.sub(r\"won\\'t\", \"will not\", text)\n",
    "    text = re.sub(r\"can\\'t\", \"can not\", text)\n",
    "    text = re.sub(r\"gonna\", \"going to\", text)\n",
    "    text = re.sub(r\"n\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'s\", \" is\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'m\", \" am\", text)\n",
    "    \n",
    "    ## clean (convert \\n or \\t to \" \", lower case, remove punctuations, strip, remove hyperlinks)\n",
    "    text = re.sub(r'\\n', ' ', text)\n",
    "    text = re.sub(r'\\t', ' ', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'http\\S+', '', str(text).lower().strip())\n",
    "    \n",
    "    ## tokenize (make a list of text)\n",
    "    lst_text = text.split()\n",
    "    \n",
    "    ## remove stopwords\n",
    "    if lst_stopwords is not None:\n",
    "        lst_text = [word for word in lst_text if word not in lst_stopwords]\n",
    "        \n",
    "    ## stemming (remove -ing, -ly, ...)\n",
    "    if use_stem == True:\n",
    "        ps = nltk.stem.porter.PorterStemmer()\n",
    "        lst_text = [ps.stem(word) for word in lst_text]\n",
    "    \n",
    "    ## lemmatization (convert word into base form)\n",
    "    if use_lemm == True:\n",
    "        lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "        lst_text = [lem.lemmatize(word) for word in lst_text]\n",
    "        \n",
    "    ## join lst back to string\n",
    "    \n",
    "    text = \" \".join(lst_text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38d9bb76-118f-42a1-a1d4-2f8573f78061",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"clean\"] = [preprocess_text(x, use_stem=False, use_lemm=False, lst_stopwords=lst_stopwords) for x in dataset[\"doc\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5d69b72-553b-44f4-aefc-46cd9979180d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop([\"label\"], axis=1)\n",
    "y = dataset[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f9114a3-c3b1-4393-b90a-d57ff15365ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_w, X_test_w, y_train_w, y_test_w = train_test_split(X, y, test_size = 0.33, shuffle=True, random_state=42)\n",
    "\n",
    "X_train_w.reset_index(inplace=True, drop=True)\n",
    "X_test_w.reset_index(inplace=True, drop=True)\n",
    "y_train_w.reset_index(inplace=True, drop=True)\n",
    "y_test_w.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ce58f22a-cfc5-4de8-ab4c-d6caaacdd6b4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = X[\"clean\"]\n",
    "\n",
    "## create list of lists of unigrams\n",
    "lst_corpus = []\n",
    "for string in corpus:\n",
    "    lst_words = string.split()\n",
    "    lst_grams = [\" \".join(lst_words[i:i+1]) for i in range(0, len(lst_words), 1)]\n",
    "    lst_corpus.append(lst_grams)\n",
    "\n",
    "## detect bigrams and trigrams\n",
    "bigrams_detector = gensim.models.phrases.Phrases(lst_corpus, min_count=5, threshold=10)\n",
    "bigrams_detector = gensim.models.phrases.Phraser(bigrams_detector)\n",
    "trigrams_detector = gensim.models.phrases.Phrases(bigrams_detector[lst_corpus], min_count=5, threshold=10)\n",
    "trigrams_detector = gensim.models.phrases.Phraser(trigrams_detector)\n",
    "\n",
    "model = gensim.models.word2vec.Word2Vec(lst_corpus, vector_size=300, window=8, min_count=1, sg=1, epochs=30)\n",
    "model.wv[\"opioid\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ceaa3f2d-9e70-4aa1-af8c-bce788e01ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_dict = dict(zip(model.wv.index_to_key, model.wv.vectors))\n",
    "model.save(\"embeddings_model1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "69ed4494-f48b-4ec2-bc7e-c255d9641ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Train-only w2v\n",
    "corpus = X_train_w[\"clean\"]\n",
    "\n",
    "## create list of lists of unigrams\n",
    "lst_corpus = []\n",
    "for string in corpus:\n",
    "    lst_words = string.split()\n",
    "    lst_grams = [\" \".join(lst_words[i:i+1]) for i in range(0, len(lst_words), 1)]\n",
    "    lst_corpus.append(lst_grams)\n",
    "\n",
    "## detect bigrams and trigrams\n",
    "bigrams_detector = gensim.models.phrases.Phrases(lst_corpus, min_count=5, threshold=10)\n",
    "bigrams_detector = gensim.models.phrases.Phraser(bigrams_detector)\n",
    "trigrams_detector = gensim.models.phrases.Phrases(bigrams_detector[lst_corpus], min_count=5, threshold=10)\n",
    "trigrams_detector = gensim.models.phrases.Phraser(trigrams_detector)\n",
    "\n",
    "model2 = gensim.models.word2vec.Word2Vec(lst_corpus, vector_size=300, window=8, min_count=1, sg=1, epochs=30)\n",
    "model2.wv[\"opioid\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6455a98e-8429-46b9-80eb-174f2c005751",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_dict = dict(zip(model2.wv.index_to_key, model2.wv.vectors))\n",
    "model2.save(\"embeddings_model2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c470e9af-3e78-4604-8eaf-eb51e453e78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of word embeddings 3009\n",
      "length of word embeddings 2406\n"
     ]
    }
   ],
   "source": [
    "print(f'length of word embeddings {len(model.wv.key_to_index.keys())}')\n",
    "print(f'length of word embeddings {len(model2.wv.key_to_index.keys())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930b317b-1f78-4dda-9595-f476db2b8877",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
